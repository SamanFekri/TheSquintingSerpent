# BFS-Shaped Lidar DQN Snake

DQN policy that keeps the lidar-enhanced observation space but adds **BFS-based reward shaping** to nudge the agent toward safer routes.

> üß≠ **Design note**: BFS shaping works alongside the intentionally limited first-person vision window, helping the agent avoid overfitting to any single map while still reasoning locally.

## Feature summary
- ‚úÖ 3-channel local vision
- ‚úÖ Hunger scalar for reward shaping
- ‚úÖ Food ‚Äúsmell‚Äù (relative dx, dy)
- ‚úÖ Lidar beams for wall/body distance estimates
- ‚úÖ BFS-based reward shaping for safety and space awareness
- ‚úÖ Compact vision encoder (small window) keeps the CNN small while shaping guides exploration

## Observation space
- Local grid `(2N+1)x(2N+1)` with walls, body, food (3 channels).
- Hunger scalar in `[0, 1]`.
- Smell vector `(dx, dy)` toward the food.
- Lidar vector `(2 * num_rays,)` with normalized distances to the body and to walls.

## Reward shaping (environment-side)
- **BFS to food**: when no path exists, apply `--bfs_space_penalty` (default `0.5`).
- **BFS to tail**: when the tail is unreachable, apply `--bfs_tail_penalty` (default `0.5`).
- **Custom death penalty** via `--death_penalty` (default `5.0`).

The BFS results are *not* given to the agent‚Äîonly the reward signal changes.

## Training
Run from inside `bfs/`:
```bash
cd bfs
python train.py \
  --map ../maps/map_10x10.txt \
  --N 2 \             # vision radius
  --num_rays 16 \      # lidar beams
  --bfs \              # enable BFS shaping (default)
  --bfs_space_penalty 0.5 \    # unreachable-food penalty
  --bfs_tail_penalty 0.5 \     # unreachable-tail penalty
  --death_penalty 5.0 \        # extra loss on death
  --games 2000
```

## Playing
```bash
cd bfs
python play.py \
  --map ../maps/map_10x10.txt \
  --N 2 \
  --num_rays 16 \
  --wrap \
  --model models/best.pt
```
Add `--human` to take control manually.
